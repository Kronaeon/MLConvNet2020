{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2ee9d9",
   "metadata": {},
   "source": [
    "# Implementation of ConvNeXt: A ConvNet for the 2020s\n",
    "\n",
    "This notebook implements the ConvNeXt architecture as described in the paper \"A ConvNet for the 2020s\" by Liu et al. ConvNeXt is a pure convolutional neural network architecture designed to match or exceed the performance of Vision Transformers while maintaining the simplicity and efficiency of traditional ConvNets.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction]\n",
    "2. [Setup and Imports]\n",
    "3. [Architecture Implementation]\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "The paper \"A ConvNet for the 2020s\" explores the design space of convolutional neural networks by gradually \"modernizing\" a standard ResNet toward the design of a vision Transformer. The authors discover several key components that contribute to the performance difference along the way, resulting in the ConvNeXt architecture.\n",
    "\n",
    "Key innovations of ConvNeXt include:\n",
    "\n",
    "- Replacing the traditional stem with a \"patchify\" layer (4×4 non-overlapping convolution)\n",
    "- Using depthwise convolutions with larger kernel sizes (7×7)\n",
    "- Adopting an inverted bottleneck design\n",
    "- Reducing the number of activation functions and normalization layers\n",
    "- Substituting BatchNorm with LayerNorm\n",
    "- Adding separate downsampling layers between stages\n",
    "\n",
    "These modifications allow ConvNeXt to achieve performance comparable to or better than Swin Transformers across various vision tasks while maintaining the simplicity of standard ConvNets.\n",
    "\n",
    "## 2. Setup and Imports\n",
    "\n",
    "Let's start by installing and importing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "439908be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages (if needed)\n",
    "# !pip install torch torchvision timm matplotlib numpy pandas seaborn tqdm ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d8ff6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "from timm.data.transforms import RandomResizedCropAndInterpolation\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa4612",
   "metadata": {},
   "source": [
    "## 3. Architecture Implementation\n",
    "\n",
    "Now, let's implement the core components of the ConvNeXt architecture:\n",
    "\n",
    "### 3.1 LayerNorm Implementation\n",
    "\n",
    "The ConvNeXt architecture uses LayerNorm instead of BatchNorm, with support for both channels_last and channels_first formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38078081",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    LayerNorm that supports two data formats: channels_last (default) or channels_first.\n",
    "    channels_last = (batch_size, height, width, channels)\n",
    "    channels_first = (batch_size, channels, height, width)\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError\n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93caaecf",
   "metadata": {},
   "source": [
    "### 3.2 ConvNeXt Block Implementation\n",
    "\n",
    "The ConvNeXt Block is the fundamental building block of the architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13563f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    ConvNeXt Block. There are two equivalent implementations:\n",
    "    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n",
    "    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n",
    "    \n",
    "    We use (2) as it's slightly faster in PyTorch.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)  # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim)  # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "                                requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
